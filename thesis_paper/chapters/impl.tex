\chapter{Developer Documentation} % Developer guide
\label{ch:impl}

Histopathologic Cancer Detection program is divided into four major segments (\textcolor{red}{\autoref{fig:dirdiag}}):
\begin{enumerate}
	\itemsep 0em
	\item Data - includes dataset creation, analysis and visualization
	\item Networks - includes creation, training, testing of convolutional neural networks
	\item Experiments - includes hyperparameter tuning, network performance assessment and visualization
	\item Graphical User Interface - includes creation of all application windows and their interconnection
\end{enumerate}

\begin{figure}[h]
	\centering
	\includegraphics[scale=1.15]{directory_diagram.jpg}
	\caption{Diagram of directories and scripts of Histopathologic Cancer Detection}
	\label{fig:dirdiag}
\end{figure}

\section{Use-Case Diagram}

One of the main goals of the Histopahtologic Cancer Detection program was the ease of use, i.e. straightforward graphical user interface which makes complex operations look quite simple and effortless. Even though there are extremely advanced algorithms with millions of parameters behind the program, GUI was made in such a way that everyone can use it. 

First step is loading the image and selecting tissue type (breast or colorectal tissue), after which classification is being done. At every step of the way, current work can be saved, and new image can be loaded to start the process from scratch. After the classification, it is possible to visualize network representations and perform further analysis of the results by visualizing layer activations, network filters and heatmap (\textcolor{red}{\autoref{fig:usecase}}).

\begin{figure}[h]
	\centering
	\includegraphics[scale=1]{use_case.jpg}
	\caption{Use-Case Diagram of Histopathologic Cancer Detection}
	\label{fig:usecase}
\end{figure}

\section{Class Diagrams}

Classes of Histopathologic Cancer Detection can be divided into two main components: neural network classes and window classes.

Window class is the base class of all window classes, and it implements common methods, such as setting up window size and central widget. On the other side, Main Window class is the central point of GUI, as it is window which opens when program is run, and every other window is invoked from it (\textcolor{red}{\autoref{fig:class2}}). Window classes, along with their attributed and methods, will be discussed in detail in Section \textcolor{red}{\ref{gui}}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{main_class_diagram.png}
	\caption{Class Diagram of Window classes of Histopathologic Cancer Detection}
	\label{fig:class2}
\end{figure}

\clearpage

BaseCNN class is the common class of all neural network classes, and it contains common attributes, such as dataset name, network name, compile parameters, and common methods, such as creation of data generators, compilation and training of the network. Neural network classes will be discussed in more detail in Section \textcolor{red}{\ref{cnn}}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{nets_class_diagram.png}
	\caption{Class Diagram of Neural Network classes of Histopathologic Cancer Detection}
	\label{fig:class1}
\end{figure}

\section{Creation of Datasets}

Performance and accuracy of convolutional neural networks relies largely on datasets, i.e. on quality of available data, dataset size, class balance, etc. But before feeding data to the network, when using Keras API, certain dataset structure must be satisfied. More precisely, dataset must have following structure: train, validation and test directories, each with identical subdirectories for each class. Scripts responsible for creation of required directory structure are:
\begin{itemize}
	\itemsep 0em
	\item \emph{\textbf{break\_his\_dataset\_creation.py}},
	\item \emph{\textbf{nct\_crc\_he\_100k\_dataset\_creation.py}}.
\end{itemize} 
They work by extracting datasets downloaded from \cite{breakhis_bib}, \cite{nctcrche100k_bib}, creating necessary directory tree and distributing images between created subdirectories. After executing scripts, datasets are ready to be fed into convolutional neural networks in order to train them, but before that, neural network architecture is to be built.
\clearpage

\section{Convolutional Neural Networks} \label{cnn}

Convolutional Neural Networks for image classification take image as an input, \textbf{process} it, and output category to which that image belongs. Processing part consists of a series of layers through which we propagate image in order to learn features, which in turn determine to which class an image belongs. (\textcolor{red}{\autoref{fig:cnn1}}).

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{cnn.png}
	\caption{Convolutional Neural Network consisting of two Convolution layers, two Max-Pooling layers, Flatten layer and two Fully-Connected (Dense) layers}
	\label{fig:cnn1}
\end{figure}

Most commonly used layers in CNN architectures are convolution layer, max-pooling layer, flatten layer, dense layer and dropout layer.

\subsection{Convolution Layer}

Convolution layer is the building block of the CNN architecture. Its primary purpose is to extract features from input image, such as edges, lines, curves, colors. As we go deeper inside the network, it starts identifying more complex features, such as shapes, objects. This layer consists of multiple filters (usually 3x3 matrices) whose parameters need to be learned, and it performs dot products between parts of an image and these filters.

\subsection{Max-Pooling Layer}

Max-Pooling layer is located after a series of convolution layers in CNN architecture. It is a downsampling method which reduces dimensionality, thus decreasing number of parameters and computational power needed in order to train the network, while retaining important features and patterns. It is achieved by applying a max filter to non-overlapping subregions (usually 2x2 matrices), thus reducing the size of each feature map by a factor of 2, and discarding 75\% of acivations in the process.

\subsection{Flatten Layer}

Output of the convolutional base of the network (series of convolution and max-pooling layers) is a two-dimensional matrix, and before feeding that data to the classification top of the network, it needs to be transformed. Flatten layer reshapes the output matrix to vector, thus removing all dimensions but one in the process, making the data prepared for the series of fully-connected layers.

\subsection{Fully-Connected Layer}

After the high-level features of the image have been detected, series of fully-connected (dense) layers is attached to the top of the network in order to classify image into a label. Dense layers consist of huge number of nodes (neurons), which provide a way of learning non-linear combinations of features outputted by convolutional base, and determine which feature most correlate to a particular class.

\subsection{Dropout Layer}

Fully-Connected layer contains the most parameters in the network, and as a result neurons develop co-dependency amongst each other during training, which leads to over-fitting the data (not generalizing well on new, unseen images). In order to prevent that, dropout layers are positioned right after dense layers in CNN architecture as a means of regularizing the network. Dropout consists of randomly ignoring (dropping out) fraction of neurons of fully-connected layer, which in turn makes network learn more robust features, and achieve better performance.
\clearpage

\subsection{CNNSimple Implementation}

Text.

\subsection{Transfer Learning}

Text.

\subsection{VGG19 Simple Implementation}

Text.

\section{Experiments and Results}

Text.

\section{Graphical User Interface} \label{gui}

Text.

\section{Implementing Additional Features}

Text.
