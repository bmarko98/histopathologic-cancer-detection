
network_name: CNNSimpleTest
dataset_name: nct_crc_he_100k
dataset_count: (70010, 14995, 14995)
classes: ['ADI', 'BACK', 'CAS', 'CAE', 'DEB', 'LYM', 'MUC', 'NCM', 'SM']
image_size: (150, 150)
data_augmentation: True
batch_size: 32
loss: categorical_crossentropy
learning_rate: 2e-05
optimizer: rmsprop
metrics: ['acc']
epochs: 50
train_generator: <keras.preprocessing.image.DirectoryIterator object at 0x7fc67a986c88>
validation_generator: <keras.preprocessing.image.DirectoryIterator object at 0x7fc67a986f28>
test_generator: <keras.preprocessing.image.DirectoryIterator object at 0x7fc67a986da0>
model: <keras.engine.sequential.Sequential object at 0x7fc67a986e10>
history: <keras.callbacks.callbacks.History object at 0x7fc668c0f588>
predictions: [0 0 0 ... 8 8 8]


Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
block1_conv1 (Conv2D)        (None, 148, 148, 32)      896       
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 146, 146, 32)      9248      
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 73, 73, 32)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 71, 71, 64)        18496     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 69, 69, 64)        36928     
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 34, 34, 64)        0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 32, 32, 128)       73856     
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 30, 30, 128)       147584    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 28, 28, 128)       147584    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 14, 14, 128)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 12, 12, 256)       295168    
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 10, 10, 256)       590080    
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 8, 8, 256)         590080    
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 4, 4, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4096)              0         
_________________________________________________________________
dense1 (Dense)               (None, 512)               2097664   
_________________________________________________________________
dropout1 (Dropout)           (None, 512)               0         
_________________________________________________________________
dense2 (Dense)               (None, 1024)              525312    
_________________________________________________________________
dropout2 (Dropout)           (None, 1024)              0         
_________________________________________________________________
prediction (Dense)           (None, 9)                 9225      
=================================================================
Total params: 4,542,121
Trainable params: 4,542,121
Non-trainable params: 0
_________________________________________________________________


training and validation accuracy and loss: 

    accuracy      loss  validation accuracy  validation loss
0   0.349538  1.690189             0.469017         1.281442
1   0.512518  1.238643             0.574150         1.142303
2   0.598388  1.041256             0.659761         0.930187
3   0.660308  0.898849             0.648132         0.651069
4   0.702292  0.792492             0.743567         0.553082
5   0.737560  0.705142             0.773775         0.984207
6   0.765669  0.635369             0.788010         0.510297
7   0.788176  0.575150             0.749850         0.892801
8   0.810126  0.515535             0.818887         0.239407
9   0.829661  0.472612             0.839270         0.517264
10  0.845694  0.430940             0.846822         0.338280
11  0.859099  0.396782             0.861325         0.303457
12  0.869745  0.371816             0.853773         0.301928
13  0.877747  0.345910             0.828109         0.278114
14  0.886393  0.326806             0.878233         0.315996
15  0.893038  0.307977             0.884047         0.078793
16  0.899897  0.290729             0.878166         0.453495
17  0.906342  0.275112             0.845686         0.251994
18  0.910600  0.262481             0.891399         0.267460
19  0.914130  0.255008             0.874156         0.084245
20  0.919346  0.243449             0.915258         0.234679
21  0.921461  0.235200             0.852035         0.752182
22  0.923933  0.228942             0.894406         0.204697
23  0.927806  0.221966             0.878567         0.532692
24  0.929849  0.217212             0.904832         0.128357
25  0.930621  0.215481             0.933035         0.330781
26  0.930907  0.213201             0.906904         0.142878
27  0.932079  0.214941             0.910847         0.041969
28  0.932107  0.214555             0.915859         0.167969
29  0.933079  0.215987             0.901357         0.232822
30  0.932850  0.216162             0.904565         0.249876
31  0.932050  0.222230             0.871015         0.339910
32  0.932150  0.223731             0.911181         0.614074
33  0.931450  0.227214             0.931097         0.536024
34  0.928478  0.230179             0.889795         0.547348
35  0.928849  0.236939             0.920404         0.163508
36  0.927920  0.246563             0.928223         0.120919
37  0.926377  0.253232             0.901022         0.173765
38  0.924605  0.258186             0.893604         0.155973
39  0.923533  0.260549             0.915458         0.193910
40  0.921575  0.270731             0.914522         0.102945
41  0.921361  0.269239             0.822896         0.888070
42  0.919375  0.282420             0.915057         0.199960
43  0.918803  0.283634             0.942725         0.011469
44  0.917888  0.292702             0.810733         0.817002
45  0.917060  0.312649             0.909777         0.545227
46  0.913987  0.310418             0.876963         0.180419
47  0.911915  0.312364             0.921673         0.613481
48  0.913101  0.351368             0.893938         0.327719
49  0.910494  0.345491             0.913320         0.177291

test accuracy: 0.913528323173523
test loss: 0.2785138487815857